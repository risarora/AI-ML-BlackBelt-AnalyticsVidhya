# NLP
* AI overview
  * A brief history of AI
  * Types of AI systems
  * Training machine learning models
  * Applying models for prediction
  * Demos and Labs
* AI with TensorFlow and Keras
  * Google democratization of AI with TensorFlow
  * Types of neural network (Perceptron, CNN, RNN) and their uses
  * Natural Language Processing with TensorFlow
  * Use cases and labs
  * Text Preparation
  * Bag-of-words
  * Bag-of-n-Grams
  * Filtering
  * Stopwords
  * Frequency-based
  * Stemming
  * Parsing and tokenization
  * TF-IDF
  * SpaCy for semantic pipeline and named entity recognition
* NLP and Deep Learning
  * Word2vec
  * Learning word embedding
  * The Skip-gram Model
  * Building the graph
  * Training the model
  * Visualizing the embeddings
  * Optimizing the implementation
  * Text classification with TensorFlow
  * Linear models and SVM
  * Working with Unicode
  * Automatic translation (seq2seq)
  * Text generation with RNN
  * Named entity extraction with RNNs (sequence modeling)
  * Bidirectional LSTM with attention
  * Transformer architecture
  * Context-aware representations using pretrained language models (ELMo, BERT, ULMFiT)
  * Natural Language Processing pipelines
* Conversational AI (Optional)
  * Introduction to the Rasa framework
  * Generating natural language
  * Understanding natural language
  * Chatbots
* Unsupervised NLP (Optional)
  * LDA (Latent Dirichlet Allocation)
  * Topic modeling with gensim
  * Applications of topic modeling
