# NLP
## Basic Steps of NLP

* Tokenization
* Text Normalization
* Parts-of-Speech Tagging
* Dependency Parsing

## Corpus, Token and N-Grams
Corpus is a collection of text data
Token
N-Grams groups of N words.
* Unigrams
* Bigrams
* TriGrams

## Tokenization
* White Space Tokenization
* Reg Ex Tokenization

## Normalization
* Convert tokens to base form of a word aka Morpheme
* Structure of token : **prefix** - **morpheme** - **suffix**

### Techniques of  Normalization:

* Stemming - Primitive

---|---|---

* Lemmitization - Advanced based on vocabulary, word structure, part of speech tags and grammer relations .
Run



#### Part of Speech Tags
  Nouns
  Verbs
  Adjectives
  Adverbs

##### Defined by relations
  Text Cleaning
  Feature Engineering tasks
  Word sense disambiguous

#### Consituency Grammer
##### Dependency Grammer


Used for :-
* Named entity recognition
* Question Answering System
* Coreference Resolution
*
